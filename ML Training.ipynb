{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Linear Regression, Logistic Regression, KNN, K-Means, PCA, Decision Trees / Random Forests, Naive Bayes, \n",
    "Neural Network, Ridge Regression\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = \"/Users/jeremynixon/Dropbox/python/Ultimate Frisbee/Indoor.csv\"\n",
    "dataset = pd.read_csv(file)\n",
    "x_train = dataset['Goals']\n",
    "x_train = np.column_stack((np.ones(len(x_train)), x_train))\n",
    "y_train = np.array(dataset['Assists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "\n",
    "def linear_regression(x, y, lr=.0001, ep = .0000001, num_iter = 100000):\n",
    "    rows, cols = x.shape\n",
    "    betas = np.zeros(cols)\n",
    "    betas = betas + lr * sum([(y[i] - np.dot(x[i], betas)) * x[i] for i in range(rows)])\n",
    "    sse = sum([(y[i] - np.dot(x[i], betas))**2 for i in range(rows)])\n",
    "    for i in xrange(num_iter):\n",
    "        betas = betas + lr * sum([(y[i] - np.dot(x[i], betas)) * x[i] for i in range(rows)])\n",
    "        e = sum([(y[i] - np.dot(x[i], betas))**2 for i in range(rows)])\n",
    "        if abs(e - sse) <= ep:\n",
    "            return betas\n",
    "        sse = e\n",
    "    return 'Failed to Converge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.40663308,  0.74461107])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_thetas(x, y, lr = .0001, ep = .00001, num_iter = 100000):\n",
    "    rows, cols = x.shape\n",
    "    thetas = np.zeros(cols)\n",
    "    thetas = thetas + lr * sum([(y[i] - np.dot(thetas, x[i])) * x[i] for i in xrange(rows)])\n",
    "    sse = sum([(y[i] - np.dot(x[i], thetas))**2 for i in xrange(rows)])\n",
    "    for i in xrange(num_iter):\n",
    "        thetas = thetas + lr * sum([(y[i] - np.dot(thetas, x[i])) * x[i] for i in xrange(rows)])\n",
    "        e = sum([(y[i] - np.dot(x[i], thetas))**2 for i in xrange(rows)])\n",
    "        if abs(e-sse) < ep:\n",
    "            return thetas\n",
    "        sse = e\n",
    "    return 'Did Not Converge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.40306998,  0.74491024])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_thetas(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr(x, y):\n",
    "    xt = x.T\n",
    "    xtx = np.dot(xt, x)\n",
    "    inv = np.linalg.inv(xtx)\n",
    "    weights = np.dot(inv, np.dot(xt, y))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.407029  ,  0.74457783])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.cross_validation\n",
    "\n",
    "iris = pd.read_csv('/Users/jeremynixon/Dropbox/python/Oracle Development/iris.data', header=None)\n",
    "iris = iris[:100]\n",
    "y = np.array(iris[4])\n",
    "new_y = []\n",
    "for i in y:\n",
    "    if i == 'Iris-setosa':\n",
    "        new_y.append(1)\n",
    "    elif i == 'Iris-versicolor':\n",
    "        new_y.append(0)\n",
    "y = np.array(new_y)\n",
    "x = np.array(iris.drop([4], 1))\n",
    "x = np.hstack((np.ones((x.shape[0],1)),x))\n",
    "x_train, x_test, y_train, y_test = sklearn.cross_validation.train_test_split(x, y, test_size = .20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import e\n",
    "def h(x, thetas):\n",
    "    return e**(np.dot(x, thetas))/(1.0 + e**np.dot(x, thetas))\n",
    "\n",
    "def logistic_regression(x, y, lr = .001, num_iters = 1000):\n",
    "    rows, cols = x.shape\n",
    "    thetas = np.ones(cols)\n",
    "    indices = np.arange(rows)\n",
    "    for iteration in xrange(num_iters):\n",
    "        permutation = np.random.permutation(indices)\n",
    "        for i in permutation:\n",
    "            thetas = thetas + lr * (y[i] - h(x[i], thetas)) * x[i]\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] [0, 0] [0, 0] [1, 1] [1, 1] [1, 1] [1, 1] [0, 0] [1, 1] [1, 1] [1, 1] [1, 1] [0, 0] [1, 1] [0, 0] [1, 1] [0, 0] [0, 0] [1, 1] [1, 1]\n"
     ]
    }
   ],
   "source": [
    "thetas = logistic_regression(x_train, y_train)\n",
    "for i, v in enumerate(x_test):\n",
    "    n = np.dot(thetas, v)\n",
    "    if n > 0:\n",
    "        n = 1\n",
    "    else:\n",
    "        n = 0\n",
    "    print [n, y_test[i]],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.   5.6  3.   4.1  1.3]\n",
      "[ 1.   5.   3.4  1.6  0.4]\n",
      "7.58\n",
      "0.0\n",
      "7.58\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print x_train[1]\n",
    "print x_train[2]\n",
    "print ed(x_train[1], x_train[2])\n",
    "print ed(x_train[1], x_train[1])\n",
    "print eucledian_distance(x_train[1], x_train[2])\n",
    "print eucledian_distance(x_train[1], x_train[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eucledian_distance(vector1, vector2):\n",
    "    return sum([(i**2) for i in vector1-vector2])\n",
    "\n",
    "def get_neighbors(x, point, k):\n",
    "    d = []\n",
    "    for i, v in enumerate(x):\n",
    "        d.append([i, eucledian_distance(v, point)])\n",
    "    d.sort(key = lambda t:t[1])\n",
    "    \n",
    "    n = []\n",
    "    for i in xrange(k):\n",
    "        n.append(d[i][0])\n",
    "    return n\n",
    "\n",
    "def get_outcome(n, y):\n",
    "    ht = {}\n",
    "    for i in n:\n",
    "        try:\n",
    "            ht[y[i]] += 1\n",
    "        except KeyError:\n",
    "            ht[y[i]] = 1\n",
    "    \n",
    "    maximus = 0\n",
    "    for i, v in ht.iteritems():\n",
    "        if v > maximus:\n",
    "            maximus = v\n",
    "            max_index = i\n",
    "    \n",
    "    return max_index\n",
    "    \n",
    "        \n",
    "def KNN(x_train, y_train, x_test, k):\n",
    "    predictions = []\n",
    "    for i in x_test:\n",
    "        neighbors = get_neighbors(x_train, i, k)\n",
    "        predictions.append(get_outcome(neighbors, y_train))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1]\n",
      "[0 0 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print KNN(x_train, y_train, x_test, 4)\n",
    "print y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = \"/Users/jeremynixon/Dropbox/python/Ultimate Frisbee/Indoor.csv\"\n",
    "dataset = pd.read_csv(file)\n",
    "for_cluster = dataset[['Games','Goals','Assists','Ds','Turns','Drops']]\n",
    "for_cluster = np.array(for_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# May not assign a datapoint to every cluster, and so can lose clusters\n",
    "# Convergence check is buggy, will return true if it finds the first one to be correct\n",
    "\n",
    "def ed(v1, v2):\n",
    "    return sum([(i**2) for i in v1-v2])\n",
    "\n",
    "def get_clusters(x, means):\n",
    "    clusters = {}\n",
    "    for point in x:\n",
    "        minimum = float('inf')\n",
    "        for i, v in enumerate(means):\n",
    "            d = ed(v, point)\n",
    "            if d < minimum:\n",
    "                min_index = i\n",
    "                minimum = d\n",
    "        try:\n",
    "            clusters[min_index].append(point)\n",
    "        except KeyError:\n",
    "            clusters[min_index] = [point]\n",
    "            \n",
    "    return clusters\n",
    "\n",
    "def get_means(x, clusters):\n",
    "    means = []\n",
    "    for i, v in clusters.iteritems():\n",
    "        means.append(np.mean(v))\n",
    "    return means\n",
    "        \n",
    "\n",
    "def converged(means, oldmeans):\n",
    "    for i in means:\n",
    "        for j in oldmeans:\n",
    "            if (i == j).all():\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "#    return set([tuple(a) for a in means]) == set([tuple(a) for a in oldmeans])\n",
    "            \n",
    "\n",
    "def k_means(x, k):\n",
    "    means = random.sample(x, k)\n",
    "    oldmeans = random.sample(x, k)\n",
    "    while(not converged(means, oldmeans)):\n",
    "        oldmeans = means\n",
    "        clusters = get_clusters(x, means)\n",
    "        means = get_means(x, clusters)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [array([ 6, 15, 16,  7, 12,  2]),\n",
       "  array([ 5, 14, 13,  7, 11,  0]),\n",
       "  array([ 6,  8, 15,  3, 10,  0]),\n",
       "  array([ 7, 11, 14,  8, 11,  0]),\n",
       "  array([ 7, 23,  5,  6,  5,  0]),\n",
       "  array([ 8, 18,  4,  5,  5,  4]),\n",
       "  array([ 7, 16, 15,  4, 16,  0]),\n",
       "  array([ 8, 19,  3,  1, 13,  5]),\n",
       "  array([ 8, 10,  7,  6,  6,  1]),\n",
       "  array([ 7, 13, 13,  6, 14,  2]),\n",
       "  array([ 5, 27, 13, 11,  4,  2]),\n",
       "  array([ 6, 12, 17, 11,  7,  3]),\n",
       "  array([ 6, 12,  7,  6,  8,  3]),\n",
       "  array([ 4,  8, 14,  5,  8,  2]),\n",
       "  array([ 6, 13,  0,  6, 12,  4]),\n",
       "  array([ 6, 18, 10,  8,  5,  1]),\n",
       "  array([ 5,  7, 15,  3, 11,  2]),\n",
       "  array([ 6,  7, 10,  0, 18,  1])],\n",
       " 1: [array([ 4, 13,  4,  7,  6,  3]),\n",
       "  array([ 5,  8, 12,  4,  5,  1]),\n",
       "  array([ 6, 10,  0,  4,  5,  1]),\n",
       "  array([ 5,  2,  4,  1, 11,  2]),\n",
       "  array([4, 7, 4, 2, 6, 2]),\n",
       "  array([4, 8, 5, 2, 9, 6]),\n",
       "  array([ 3,  1, 12,  5, 11,  2]),\n",
       "  array([5, 7, 4, 3, 7, 2]),\n",
       "  array([ 5, 11,  1,  2,  2,  2]),\n",
       "  array([7, 4, 4, 6, 6, 1]),\n",
       "  array([ 5, 10,  4,  1,  4,  1]),\n",
       "  array([4, 8, 2, 0, 5, 0]),\n",
       "  array([5, 8, 5, 5, 0, 4]),\n",
       "  array([5, 9, 5, 3, 7, 1]),\n",
       "  array([ 3,  5, 14,  3,  6,  0]),\n",
       "  array([2, 1, 6, 4, 8, 0]),\n",
       "  array([6, 5, 4, 7, 8, 1]),\n",
       "  array([ 5,  3, 15,  1,  9,  0]),\n",
       "  array([6, 2, 6, 6, 6, 0]),\n",
       "  array([ 4, 11,  6,  3,  7,  1]),\n",
       "  array([ 5,  7, 13,  2, 10,  0]),\n",
       "  array([4, 4, 3, 1, 3, 4]),\n",
       "  array([ 6,  5,  7,  1, 11,  2]),\n",
       "  array([6, 8, 2, 2, 1, 1]),\n",
       "  array([3, 2, 4, 1, 7, 0]),\n",
       "  array([5, 3, 8, 2, 5, 4]),\n",
       "  array([6, 5, 3, 1, 9, 2]),\n",
       "  array([ 4,  4,  9,  2, 13,  1]),\n",
       "  array([3, 5, 4, 1, 9, 0]),\n",
       "  array([ 3,  5,  4,  1, 10,  1]),\n",
       "  array([2, 8, 2, 3, 3, 0]),\n",
       "  array([5, 9, 1, 5, 6, 1]),\n",
       "  array([3, 2, 2, 2, 8, 2]),\n",
       "  array([6, 7, 1, 4, 1, 0]),\n",
       "  array([3, 3, 6, 2, 8, 1]),\n",
       "  array([3, 6, 8, 6, 6, 1]),\n",
       "  array([3, 1, 7, 4, 5, 0]),\n",
       "  array([3, 7, 1, 6, 2, 0]),\n",
       "  array([5, 5, 2, 1, 4, 1]),\n",
       "  array([5, 4, 2, 1, 3, 4])],\n",
       " 2: [array([ 7, 20, 36, 14, 15,  1]),\n",
       "  array([ 6, 18, 20, 10, 17,  4]),\n",
       "  array([ 6, 15, 35,  5, 13,  3]),\n",
       "  array([ 8,  9, 27,  7, 18,  3]),\n",
       "  array([ 8, 14, 21,  5, 20,  6]),\n",
       "  array([ 7, 16, 29, 15, 15,  3]),\n",
       "  array([ 6,  4, 15,  7, 32,  3])],\n",
       " 3: [array([3, 2, 0, 1, 1, 0]),\n",
       "  array([2, 1, 1, 2, 1, 3]),\n",
       "  array([3, 2, 0, 0, 0, 1]),\n",
       "  array([2, 0, 0, 2, 0, 2]),\n",
       "  array([6, 3, 1, 0, 1, 2]),\n",
       "  array([0, 0, 0, 0, 0, 0]),\n",
       "  array([1, 0, 0, 1, 0, 0]),\n",
       "  array([1, 1, 0, 0, 2, 1]),\n",
       "  array([1, 0, 1, 0, 2, 0]),\n",
       "  array([2, 0, 0, 0, 0, 2]),\n",
       "  array([0, 0, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0]),\n",
       "  array([1, 1, 4, 0, 3, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0]),\n",
       "  array([1, 0, 0, 1, 0, 0]),\n",
       "  array([1, 1, 1, 2, 8, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 2, 0, 0]),\n",
       "  array([1, 0, 0, 1, 1, 0]),\n",
       "  array([2, 2, 0, 0, 2, 1]),\n",
       "  array([1, 1, 0, 0, 0, 0]),\n",
       "  array([2, 5, 3, 3, 0, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0]),\n",
       "  array([2, 0, 0, 0, 4, 1]),\n",
       "  array([2, 2, 3, 0, 5, 1]),\n",
       "  array([2, 0, 0, 0, 2, 0]),\n",
       "  array([3, 1, 0, 1, 2, 2]),\n",
       "  array([0, 0, 0, 0, 0, 0]),\n",
       "  array([2, 3, 1, 3, 2, 2]),\n",
       "  array([5, 1, 0, 2, 2, 2]),\n",
       "  array([1, 2, 5, 0, 1, 0]),\n",
       "  array([1, 0, 1, 0, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0]),\n",
       "  array([1, 0, 0, 1, 1, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0]),\n",
       "  array([1, 1, 3, 1, 4, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0])]}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means(for_cluster, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PCA(x):\n",
    "    M = (x - np.mean(x.T, axis=1)).T\n",
    "    cov = np.cov(M) # Covariance Matrix\n",
    "    lv, coef = np.linalg.eig(cov) # Latent Variables, Coefficients\n",
    "    proj = np.dot(coef.T, M)\n",
    "    return coef, proj, lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.18553772,  0.14628245,  0.19947737, -0.58959991,  0.7452515 ,\n",
       "          0.03685275],\n",
       "        [ 0.47287921,  0.79966225,  0.06194678,  0.06547875, -0.22566889,\n",
       "         -0.27905953],\n",
       "        [ 0.68175687, -0.40519258, -0.57387528, -0.00202164,  0.07127181,\n",
       "         -0.19133728],\n",
       "        [ 0.24870082,  0.17087247, -0.14550326,  0.05753527, -0.05741096,\n",
       "          0.93870814],\n",
       "        [ 0.45984355, -0.37912233,  0.76939554,  0.03403977, -0.22158788,\n",
       "          0.0508013 ],\n",
       "        [ 0.06213208,  0.04505072,  0.1178891 ,  0.80225394,  0.57982486,\n",
       "         -0.02009844]]),\n",
       " array([[  1.59075623e+01,   3.51509377e+01,   2.32228118e+01,\n",
       "           3.71271687e+00,   5.65770330e+00,  -8.37933853e+00,\n",
       "          -1.39208296e+00,  -7.92090152e+00,  -9.02575082e+00,\n",
       "          -9.59751323e+00,  -6.79252596e+00,  -1.05902545e+01,\n",
       "          -1.01560159e+01,  -5.58535970e-01,   1.26197671e+01,\n",
       "          -8.95001837e+00,  -4.30194571e-01,   2.35250049e+00,\n",
       "          -8.80327279e+00,   9.87689645e+00,   5.04636760e+00,\n",
       "           4.63887519e-01,  -2.23778481e+00,  -1.00949149e+01,\n",
       "          -1.05902545e+01,  -1.05902545e+01,  -3.59547838e-01,\n",
       "           2.88855168e+01,  -5.76314735e+00,   1.25026626e+01,\n",
       "           2.37618814e+01,   8.78493836e+00,   5.92415068e+00,\n",
       "          -1.05902545e+01,  -1.05902545e+01,  -5.65392318e-02,\n",
       "          -1.01560159e+01,  -5.07393065e+00,  -2.40233846e+00,\n",
       "          -1.05902545e+01,  -1.05902545e+01,   1.68532300e+01,\n",
       "           8.46135021e+00,  -9.78715440e-01,   4.70853573e+00,\n",
       "           2.02927072e+00,  -1.00928528e+01,   5.38051461e+00,\n",
       "          -9.69617239e+00,   2.26444180e+01,  -8.29160144e+00,\n",
       "          -9.93183755e+00,   2.88600878e+01,   1.37730573e+01,\n",
       "           1.66673594e+01,   1.39283992e+01,  -9.82206952e-01,\n",
       "          -5.06340993e+00,  -1.05902545e+01,   1.09618157e+00,\n",
       "           6.36971750e+00,  -1.89462325e-01,   6.32716998e+00,\n",
       "           3.47124828e+00,  -1.05902545e+01,  -8.31767276e+00,\n",
       "           7.60626497e+00,  -4.86680019e+00,  -4.03455636e+00,\n",
       "           8.52604286e+00,   3.09090997e+00,  -9.29949194e+00,\n",
       "          -3.31110349e+00,  -8.26811002e+00,  -2.89324977e+00,\n",
       "           2.55274398e-01,  -1.05902545e+01,   3.92925740e+00,\n",
       "          -6.32873082e+00,  -5.55804591e-01,   4.71672490e+00,\n",
       "          -7.64833377e+00,  -5.54925049e-01,  -5.59033046e+00,\n",
       "          -3.29494151e-02,  -9.20098426e+00,   1.92831372e+01,\n",
       "          -2.94699853e+00,  -6.60198653e-01,  -1.05902545e+01,\n",
       "          -1.05902545e+01,  -1.05902545e+01,  -3.42395497e+00,\n",
       "          -4.03047000e+00,  -2.86180376e-01,   1.02033227e+01,\n",
       "           2.57108717e+00,   9.80258724e+00,  -1.49444302e+00,\n",
       "           8.99001093e+00,  -9.69617239e+00,  -3.62983797e+00,\n",
       "          -1.05902545e+01,  -5.79849193e+00,  -1.05902545e+01,\n",
       "          -3.78444901e+00,  -4.53077551e+00],\n",
       "        [  1.92542618e+00,  -2.02014219e+00,   1.41074981e+00,\n",
       "           7.21563244e+00,  -1.01533518e-01,   6.29060254e-01,\n",
       "           6.50638440e+00,  -4.16052390e-01,   8.82360838e-01,\n",
       "          -4.76450453e-01,   1.38160624e+00,  -1.20086172e+00,\n",
       "          -8.83706810e-01,  -4.40026700e+00,   2.48408011e+00,\n",
       "          -9.68110958e-01,   1.51824590e+00,   9.55551475e-01,\n",
       "          -2.21801651e+00,  -3.28236364e+00,  -8.05054493e+00,\n",
       "           1.45627848e+00,   7.59524439e+00,  -8.18195384e-01,\n",
       "          -1.20086172e+00,  -1.20086172e+00,   1.96545629e-01,\n",
       "          -6.44904939e+00,  -2.96800361e+00,   1.43338138e-01,\n",
       "          -9.26678405e+00,   1.53190074e+01,   1.18815016e+01,\n",
       "          -1.20086172e+00,  -1.20086172e+00,   4.60583656e+00,\n",
       "          -8.83706810e-01,  -3.35134329e+00,   3.07556926e+00,\n",
       "          -1.20086172e+00,  -1.20086172e+00,   1.15735531e+00,\n",
       "           9.41493867e+00,   4.93645082e+00,   3.92522383e+00,\n",
       "           2.60535968e+00,  -8.59116791e-01,  -4.19851583e+00,\n",
       "          -1.26282914e+00,  -3.80215474e+00,  -2.21662623e-02,\n",
       "          -2.54917026e-01,  -2.12146921e+00,   7.58844750e-01,\n",
       "           1.63071369e+01,   1.74539907e+00,  -4.88927882e+00,\n",
       "           2.38705407e+00,  -1.20086172e+00,   2.62553243e-01,\n",
       "          -7.38957993e+00,  -2.40449720e+00,   4.56384022e+00,\n",
       "           3.65320915e+00,  -1.20086172e+00,  -2.37973541e+00,\n",
       "          -3.58879564e+00,  -2.37511099e+00,   5.81047692e-01,\n",
       "          -1.97964492e+00,  -3.07057555e+00,  -1.66654148e+00,\n",
       "           5.27141911e+00,  -4.59622877e-01,  -3.26644403e+00,\n",
       "          -2.68566720e+00,  -1.20086172e+00,   6.72841195e+00,\n",
       "           9.29971524e-01,  -6.91560573e-01,  -5.60561076e+00,\n",
       "           3.81448129e-03,  -1.62570194e+00,  -1.86034001e+00,\n",
       "          -1.95977354e+00,  -1.79384346e+00,  -1.40030618e+01,\n",
       "           4.05386642e+00,   4.94699726e+00,  -1.20086172e+00,\n",
       "          -1.20086172e+00,  -1.20086172e+00,  -2.57420729e+00,\n",
       "           5.17364365e+00,  -3.44036608e+00,   9.53524644e+00,\n",
       "          -4.10029982e-01,  -4.51732921e+00,  -4.01082197e+00,\n",
       "          -5.55660827e+00,  -1.26282914e+00,   4.69741892e+00,\n",
       "          -1.20086172e+00,  -2.81611161e+00,  -1.20086172e+00,\n",
       "           1.41791047e+00,   1.13252272e+00],\n",
       "        [ -5.05801522e-01,  -1.03023211e+01,   1.03078382e+00,\n",
       "           1.35936935e+00,  -3.91055333e+00,  -5.53646884e-01,\n",
       "           3.29932093e+00,  -1.18078228e+00,  -1.05965007e+00,\n",
       "          -1.55613842e+00,  -8.58618227e-02,  -1.89986483e+00,\n",
       "          -1.84589072e+00,   5.47954038e+00,  -5.07735683e-02,\n",
       "           1.82394969e-02,   1.59731590e+00,   3.86513041e+00,\n",
       "          -7.35471652e-01,  -1.55810991e+00,  -1.54376405e-01,\n",
       "           2.42068556e+00,   6.88624036e-01,  -1.26513190e+00,\n",
       "          -1.89986483e+00,  -1.89986483e+00,   1.31000556e+00,\n",
       "          -1.02311406e+01,  -1.50786607e+00,  -5.57037690e-01,\n",
       "          -2.05689313e+00,   1.02583438e+00,   2.10651279e+00,\n",
       "          -1.89986483e+00,  -1.89986483e+00,   4.71456678e-01,\n",
       "          -1.84589072e+00,   3.65184187e+00,   2.09284602e+00,\n",
       "          -1.89986483e+00,  -1.89986483e+00,   3.60781167e+00,\n",
       "           9.59740133e+00,  -3.53224008e+00,   1.59537747e-01,\n",
       "           1.85281474e+00,  -2.19087135e+00,  -4.84608925e+00,\n",
       "          -1.07649518e+00,   3.87955731e+00,   2.79663644e-01,\n",
       "          -1.63844069e+00,  -6.44270634e+00,   2.97570248e+00,\n",
       "          -4.97746914e+00,  -5.57661879e+00,   6.90936330e-01,\n",
       "          -3.34931183e+00,  -1.89986483e+00,   2.56576279e+00,\n",
       "          -2.54571019e+00,  -2.79005017e-01,   1.65904583e+00,\n",
       "           1.20335564e+00,  -1.89986483e+00,   1.69456118e+00,\n",
       "          -5.26280244e-01,   8.66224441e-01,   5.84456728e-02,\n",
       "          -2.97720879e+00,   4.14323224e+00,   3.78809974e-02,\n",
       "          -7.58898837e-01,   3.89580075e-01,   1.76722527e+00,\n",
       "          -1.28011229e+00,  -1.89986483e+00,   8.93359083e+00,\n",
       "          -5.50885542e-01,   4.89994226e+00,   3.80997890e+00,\n",
       "           6.43031558e-01,   3.49185668e+00,  -3.67647476e+00,\n",
       "           4.37914132e+00,  -1.38697810e+00,   1.48924592e+01,\n",
       "          -2.81409589e-01,   3.08791379e+00,  -1.89986483e+00,\n",
       "          -1.89986483e+00,  -1.89986483e+00,   3.77464630e+00,\n",
       "          -6.55865949e-01,   1.42320287e+00,  -2.52587069e+00,\n",
       "          -1.65951149e+00,  -8.14360325e-01,  -1.99164821e+00,\n",
       "           7.95888293e+00,  -1.07649518e+00,  -7.75909037e-01,\n",
       "          -1.89986483e+00,  -4.27987604e-01,  -1.89986483e+00,\n",
       "           1.30947336e+00,   8.31798322e-01],\n",
       "        [  2.53111372e-01,  -3.46915334e-01,   2.38877362e+00,\n",
       "           1.92362868e+00,  -8.20691593e-01,  -1.12112344e+00,\n",
       "          -1.25507429e+00,   1.86527315e+00,  -4.10444547e-01,\n",
       "           9.65522326e-01,  -1.27949344e+00,   4.25143727e-01,\n",
       "          -1.06920912e-01,  -3.63504215e-01,  -8.55250200e-01,\n",
       "           7.71356059e-01,   4.40825867e-01,   3.81541805e+00,\n",
       "          -9.83982751e-02,  -2.10594677e+00,   9.64184786e-01,\n",
       "          -5.71989986e-02,  -1.69531902e-02,   8.50451789e-01,\n",
       "           4.25143727e-01,   4.25143727e-01,  -2.09652298e+00,\n",
       "           9.35923357e-01,   7.97309266e-01,  -2.17537265e+00,\n",
       "          -3.34706450e-01,  -1.69074200e+00,   5.45766447e-01,\n",
       "           4.25143727e-01,   4.25143727e-01,  -8.80206530e-01,\n",
       "          -1.06920912e-01,   2.86389656e-01,  -1.24327028e+00,\n",
       "           4.25143727e-01,   4.25143727e-01,  -1.90994273e+00,\n",
       "           1.45769789e+00,   1.48755811e+00,  -2.29931529e+00,\n",
       "          -7.30517069e-01,   5.40214264e-01,  -6.67720759e-01,\n",
       "          -7.28811385e-02,   2.36458800e+00,   2.47234907e-01,\n",
       "          -9.89774255e-02,   1.06736428e+00,  -4.50836841e-01,\n",
       "           1.59234415e+00,   9.16849612e-01,  -1.98247922e-01,\n",
       "          -2.60121434e-01,   4.25143727e-01,  -1.31582951e+00,\n",
       "          -1.99285094e+00,  -2.44417781e+00,   6.83429459e-01,\n",
       "          -1.19812941e-02,   4.25143727e-01,   1.84356944e-01,\n",
       "          -1.63531760e+00,   3.43289302e-01,   1.69126453e+00,\n",
       "           7.26773557e-01,  -7.62732783e-01,  -6.85976541e-01,\n",
       "          -1.64130471e+00,   4.51945451e-01,  -9.24971370e-01,\n",
       "           1.15169248e+00,   4.25143727e-01,   1.70147274e+00,\n",
       "           1.28555176e+00,  -8.22725764e-01,  -3.29694130e-01,\n",
       "          -6.69719095e-01,  -6.60455560e-01,  -9.56710553e-03,\n",
       "           1.75838152e-01,   6.69815890e-01,   1.01791612e+00,\n",
       "           4.04557915e-02,  -6.41399739e-01,   4.25143727e-01,\n",
       "           4.25143727e-01,   4.25143727e-01,   7.75154831e-01,\n",
       "          -2.39194523e+00,   3.02930811e-02,  -5.21319598e-01,\n",
       "           3.84747589e-01,   5.67220371e-02,  -8.91988791e-01,\n",
       "          -1.25935099e+00,  -7.28811385e-02,  -4.74035197e-01,\n",
       "           4.25143727e-01,   8.86520114e-02,   4.25143727e-01,\n",
       "          -1.20355702e+00,   1.10368627e+00],\n",
       "        [ -7.90155880e-01,  -1.39427782e+00,  -1.30259788e+00,\n",
       "          -7.75230710e-01,   9.02710808e-01,   3.89718947e-01,\n",
       "           3.41362769e-01,   1.62347177e+00,   1.24854265e+00,\n",
       "           1.41963186e+00,   3.68813706e+00,  -1.11569893e+00,\n",
       "          -4.27858395e-01,   1.10908010e+00,  -2.46161577e+00,\n",
       "          -4.59467227e-01,   2.86012594e-01,   1.78615131e+00,\n",
       "          -7.42351383e-01,   2.31424442e-01,   1.84776638e-01,\n",
       "           7.52265251e-01,   8.01124625e-01,   1.53445379e+00,\n",
       "          -1.11569893e+00,  -1.11569893e+00,   2.38930506e+00,\n",
       "           1.03706748e+00,  -3.95967855e-01,  -2.80245243e-01,\n",
       "           2.08864798e+00,  -2.18536903e+00,   1.99366552e+00,\n",
       "          -1.11569893e+00,  -1.11569893e+00,   2.75019294e-01,\n",
       "          -4.27858395e-01,  -2.41236950e+00,  -9.05439833e-01,\n",
       "          -1.11569893e+00,  -1.11569893e+00,  -2.21561344e+00,\n",
       "           7.33490472e-01,   3.19381114e+00,   1.99435866e+00,\n",
       "          -2.07625578e-01,  -1.23052086e+00,  -5.12243678e-01,\n",
       "          -6.49446278e-01,   1.94379339e+00,   6.01153859e-02,\n",
       "          -5.96116322e-01,   1.11733808e-01,  -1.93146837e-01,\n",
       "          -2.91419031e+00,   1.41624302e+00,  -1.42558086e+00,\n",
       "          -7.11957833e-01,  -1.11569893e+00,   9.17797936e-01,\n",
       "           9.50927204e-01,   1.65811010e+00,   7.68991826e-01,\n",
       "          -1.33294305e+00,  -1.11569893e+00,   6.82774021e-02,\n",
       "          -3.73290833e-01,  -3.90832822e-01,   2.77357179e+00,\n",
       "           1.57653181e-01,   1.39114037e+00,  -6.83716931e-02,\n",
       "           1.93641764e+00,   1.55344968e+00,  -6.54721095e-01,\n",
       "           3.60026452e+00,  -1.11569893e+00,  -2.62106428e-01,\n",
       "           3.13310277e-01,   1.54922889e+00,  -8.11561705e-01,\n",
       "           2.98654172e+00,  -1.77490353e+00,  -6.87014028e-01,\n",
       "          -1.41666655e+00,   5.90613601e-02,  -2.23100269e+00,\n",
       "          -2.12499997e+00,  -3.85946877e-01,  -1.11569893e+00,\n",
       "          -1.11569893e+00,  -1.11569893e+00,   8.33861527e-02,\n",
       "           1.39616792e+00,  -4.37020345e-01,  -9.80914079e-01,\n",
       "          -7.57951481e-01,   6.49903668e-01,   5.57061095e-02,\n",
       "          -9.19911042e-01,  -6.49446278e-01,  -1.17599640e+00,\n",
       "          -1.11569893e+00,  -1.32606338e+00,  -1.11569893e+00,\n",
       "           1.26082012e+00,   3.44755148e+00],\n",
       "        [ -2.96749784e-01,   1.26151907e+00,   1.13065655e+00,\n",
       "           2.15880487e+00,  -7.66471788e-01,   1.30996063e-01,\n",
       "           1.00830925e+00,   1.06027838e+00,  -8.78611825e-01,\n",
       "           1.49997233e+00,  -1.20774752e+00,  -4.10952571e-01,\n",
       "           5.64608324e-01,  -9.28314128e-02,   5.08864418e-01,\n",
       "          -5.71655191e-01,  -8.40280200e-01,  -1.23866688e+00,\n",
       "          -4.63834494e-01,  -1.96823406e+00,   2.33665695e+00,\n",
       "           1.86081997e-01,  -1.54885895e+00,  -3.77443953e-01,\n",
       "          -4.10952571e-01,  -4.10952571e-01,   3.88238767e+00,\n",
       "          -5.77887152e+00,  -1.28620301e+00,   2.16711939e+00,\n",
       "          -3.68687781e-01,  -1.64178360e+00,  -1.03739782e+00,\n",
       "          -4.10952571e-01,  -4.10952571e-01,  -2.66081835e+00,\n",
       "           5.64608324e-01,   1.43933007e+00,  -2.62468588e+00,\n",
       "          -4.10952571e-01,  -4.10952571e-01,  -2.92034162e+00,\n",
       "          -4.49364067e+00,   1.19729547e+00,   1.67087139e+00,\n",
       "          -5.43275905e-01,   1.46646371e+00,  -1.25348165e+00,\n",
       "           6.15409626e-01,  -2.45207078e+00,  -8.13861972e-01,\n",
       "          -6.53159353e-01,   4.61562941e+00,   3.51283335e-02,\n",
       "           2.40117055e-01,   3.82981915e+00,   2.39691271e+00,\n",
       "           5.09567857e-01,  -4.10952571e-01,   4.60678613e+00,\n",
       "          -2.53800674e+00,   4.04107787e+00,   1.10045253e+00,\n",
       "          -1.32958500e+00,  -4.10952571e-01,  -1.54140301e-01,\n",
       "          -2.28206087e+00,  -1.23546990e+00,  -9.43073256e-01,\n",
       "          -1.14985492e-01,  -1.46716910e+00,  -2.35644463e-01,\n",
       "          -8.96867738e-01,   4.20660013e-01,  -3.29545240e-01,\n",
       "          -5.43536620e-01,  -4.10952571e-01,   2.34386072e+00,\n",
       "           1.51176720e+00,  -8.03422586e-01,  -5.84080437e-01,\n",
       "           1.43307366e+00,  -1.06512124e+00,  -1.83810398e+00,\n",
       "          -1.03441838e+00,  -5.34734239e-01,   3.96016996e+00,\n",
       "           1.61304434e-02,   2.04868820e+00,  -4.10952571e-01,\n",
       "          -4.10952571e-01,  -4.10952571e-01,   1.00244188e+00,\n",
       "           1.47104380e+00,  -2.18683296e-02,   6.17292761e-01,\n",
       "           2.41150848e+00,  -1.71542286e+00,   2.09002428e+00,\n",
       "          -3.16230059e+00,   6.15409626e-01,   3.28870313e+00,\n",
       "          -4.10952571e-01,  -8.52578384e-02,  -4.10952571e-01,\n",
       "          -8.82846127e-01,  -7.14883225e-01]]),\n",
       " array([ 104.30165726,   19.60575452,   11.61520756,    1.22997075,\n",
       "           1.99525827,    3.0960945 ]))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA(for_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
    "Y = df['quality'].values\n",
    "df = df.drop('quality',1)\n",
    "x_train, x_test, y_train, y_test = sklearn.cross_validation.train_test_split(df, Y, test_size = .20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.cross_validation\n",
    "\n",
    "class Tree():\n",
    "    def __init__(self, parents = None):\n",
    "        self.parents = parents\n",
    "        self.children = []\n",
    "        self.split_feature = None\n",
    "        self.split_feature_value = None\n",
    "        self.label = None\n",
    "        \n",
    "\n",
    "def entropy(y):\n",
    "    distribution = [(list(y).count(i)/float(len(y))) for i in set(y)]\n",
    "    return -sum([p * math.log(p,2) for p in distribution])\n",
    "\n",
    "def split_data(x, y, feature_index):\n",
    "    for a in set(x[:, feature_index]):\n",
    "        data_subset = []\n",
    "        for i, point in enumerate(x):\n",
    "            if point[feature_index] == a:\n",
    "                data_subset.append([point, y[i]])\n",
    "        yield data_subset\n",
    "        \n",
    "def gain(x, y, feature_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([ 1. ,  5.1,  3.5,  1.4,  0.2]), 1], [array([ 1. ,  5.1,  3.5,  1.4,  0.3]), 1], [array([ 1. ,  5.2,  3.5,  1.5,  0.2]), 1], [array([ 1. ,  5.5,  3.5,  1.3,  0.2]), 1], [array([ 1. ,  5. ,  3.5,  1.3,  0.3]), 1], [array([ 1. ,  5. ,  3.5,  1.6,  0.6]), 1]]\n",
      "[[array([ 1. ,  4.6,  3.1,  1.5,  0.2]), 1], [array([ 1. ,  4.9,  3.1,  1.5,  0.1]), 1], [array([ 1. ,  4.8,  3.1,  1.6,  0.2]), 1], [array([ 1. ,  4.9,  3.1,  1.5,  0.1]), 1], [array([ 1. ,  4.9,  3.1,  1.5,  0.1]), 1], [array([ 1. ,  6.9,  3.1,  4.9,  1.5]), 0], [array([ 1. ,  6.7,  3.1,  4.4,  1.4]), 0], [array([ 1. ,  6.7,  3.1,  4.7,  1.5]), 0]]\n",
      "[[array([ 1. ,  5. ,  2. ,  3.5,  1. ]), 0]]\n",
      "[[array([ 1. ,  4.9,  3. ,  1.4,  0.2]), 1], [array([ 1. ,  4.8,  3. ,  1.4,  0.1]), 1], [array([ 1. ,  4.3,  3. ,  1.1,  0.1]), 1], [array([ 1. ,  5. ,  3. ,  1.6,  0.2]), 1], [array([ 1. ,  4.4,  3. ,  1.3,  0.2]), 1], [array([ 1. ,  4.8,  3. ,  1.4,  0.3]), 1], [array([ 1. ,  5.9,  3. ,  4.2,  1.5]), 0], [array([ 1. ,  5.6,  3. ,  4.5,  1.5]), 0], [array([ 1. ,  6.6,  3. ,  4.4,  1.4]), 0], [array([ 1. ,  6.7,  3. ,  5. ,  1.7]), 0], [array([ 1. ,  5.4,  3. ,  4.5,  1.5]), 0], [array([ 1. ,  5.6,  3. ,  4.1,  1.3]), 0], [array([ 1. ,  6.1,  3. ,  4.6,  1.4]), 0], [array([ 1. ,  5.7,  3. ,  4.2,  1.2]), 0]]\n",
      "[[array([ 1. ,  5.4,  3.9,  1.7,  0.4]), 1], [array([ 1. ,  5.4,  3.9,  1.3,  0.4]), 1]]\n",
      "[[array([ 1. ,  5.6,  2.5,  3.9,  1.1]), 0], [array([ 1. ,  6.3,  2.5,  4.9,  1.5]), 0], [array([ 1. ,  5.5,  2.5,  4. ,  1.3]), 0], [array([ 1. ,  5.1,  2.5,  3. ,  1.1]), 0]]\n",
      "[[array([ 1. ,  5.2,  4.1,  1.5,  0.1]), 1]]\n",
      "[[array([ 1. ,  4.5,  2.3,  1.3,  0.3]), 1], [array([ 1. ,  5.5,  2.3,  4. ,  1.3]), 0], [array([ 1. ,  6.3,  2.3,  4.4,  1.3]), 0], [array([ 1. ,  5. ,  2.3,  3.3,  1. ]), 0]]\n",
      "[[array([ 1. ,  5.7,  3.8,  1.7,  0.3]), 1], [array([ 1. ,  5.1,  3.8,  1.5,  0.3]), 1], [array([ 1. ,  5.1,  3.8,  1.9,  0.4]), 1], [array([ 1. ,  5.1,  3.8,  1.6,  0.2]), 1]]\n",
      "[[array([ 1. ,  4.9,  2.4,  3.3,  1. ]), 0], [array([ 1. ,  5.5,  2.4,  3.8,  1.1]), 0], [array([ 1. ,  5.5,  2.4,  3.7,  1. ]), 0]]\n",
      "[[array([ 1. ,  6. ,  2.2,  4. ,  1. ]), 0], [array([ 1. ,  6.2,  2.2,  4.5,  1.5]), 0]]\n",
      "[[array([ 1. ,  6.5,  2.8,  4.6,  1.5]), 0], [array([ 1. ,  5.7,  2.8,  4.5,  1.3]), 0], [array([ 1. ,  6.1,  2.8,  4. ,  1.3]), 0], [array([ 1. ,  6.1,  2.8,  4.7,  1.2]), 0], [array([ 1. ,  6.8,  2.8,  4.8,  1.4]), 0], [array([ 1. ,  5.7,  2.8,  4.1,  1.3]), 0]]\n",
      "[[array([ 1. ,  5.5,  4.2,  1.4,  0.2]), 1]]\n",
      "[[array([ 1. ,  5.7,  4.4,  1.5,  0.4]), 1]]\n",
      "[[array([ 1. ,  4.6,  3.4,  1.4,  0.3]), 1], [array([ 1. ,  5. ,  3.4,  1.5,  0.2]), 1], [array([ 1. ,  4.8,  3.4,  1.6,  0.2]), 1], [array([ 1. ,  5.4,  3.4,  1.7,  0.2]), 1], [array([ 1. ,  4.8,  3.4,  1.9,  0.2]), 1], [array([ 1. ,  5. ,  3.4,  1.6,  0.4]), 1], [array([ 1. ,  5.2,  3.4,  1.4,  0.2]), 1], [array([ 1. ,  5.4,  3.4,  1.5,  0.4]), 1], [array([ 1. ,  5.1,  3.4,  1.5,  0.2]), 1], [array([ 1. ,  6. ,  3.4,  4.5,  1.6]), 0]]\n",
      "[[array([ 1. ,  4.4,  2.9,  1.4,  0.2]), 1], [array([ 1. ,  6.6,  2.9,  4.6,  1.3]), 0], [array([ 1. ,  6.1,  2.9,  4.7,  1.4]), 0], [array([ 1. ,  5.6,  2.9,  3.6,  1.3]), 0], [array([ 1. ,  6.4,  2.9,  4.3,  1.3]), 0], [array([ 1. ,  6. ,  2.9,  4.5,  1.5]), 0], [array([ 1. ,  5.7,  2.9,  4.2,  1.3]), 0], [array([ 1. ,  6.2,  2.9,  4.3,  1.3]), 0]]\n",
      "[[array([ 1. ,  5.2,  2.7,  3.9,  1.4]), 0], [array([ 1. ,  5.8,  2.7,  4.1,  1. ]), 0], [array([ 1. ,  5.8,  2.7,  3.9,  1.2]), 0], [array([ 1. ,  6. ,  2.7,  5.1,  1.6]), 0], [array([ 1. ,  5.6,  2.7,  4.2,  1.3]), 0]]\n",
      "[[array([ 1. ,  4.7,  3.2,  1.3,  0.2]), 1], [array([ 1. ,  4.7,  3.2,  1.6,  0.2]), 1], [array([ 1. ,  5. ,  3.2,  1.2,  0.2]), 1], [array([ 1. ,  4.4,  3.2,  1.3,  0.2]), 1], [array([ 1. ,  4.6,  3.2,  1.4,  0.2]), 1], [array([ 1. ,  7. ,  3.2,  4.7,  1.4]), 0], [array([ 1. ,  6.4,  3.2,  4.5,  1.5]), 0], [array([ 1. ,  5.9,  3.2,  4.8,  1.8]), 0]]\n",
      "[[array([ 1. ,  5.4,  3.7,  1.5,  0.2]), 1], [array([ 1. ,  5.1,  3.7,  1.5,  0.4]), 1], [array([ 1. ,  5.3,  3.7,  1.5,  0.2]), 1]]\n",
      "[[array([ 1. ,  5. ,  3.6,  1.4,  0.2]), 1], [array([ 1. ,  4.6,  3.6,  1. ,  0.2]), 1]]\n",
      "[[array([ 1. ,  5.7,  2.6,  3.5,  1. ]), 0], [array([ 1. ,  5.5,  2.6,  4.4,  1.2]), 0], [array([ 1. ,  5.8,  2.6,  4. ,  1.2]), 0]]\n",
      "[[array([ 1. ,  5.1,  3.3,  1.7,  0.5]), 1], [array([ 1. ,  5. ,  3.3,  1.4,  0.2]), 1], [array([ 1. ,  6.3,  3.3,  4.7,  1.6]), 0]]\n",
      "[[array([ 1. ,  5.8,  4. ,  1.2,  0.2]), 1]]\n"
     ]
    }
   ],
   "source": [
    "for i in split_data(x, y, 2):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  5.1,  3.5,  1.4,  0.2],\n",
       "       [ 1. ,  4.9,  3. ,  1.4,  0.2],\n",
       "       [ 1. ,  4.7,  3.2,  1.3,  0.2],\n",
       "       [ 1. ,  4.6,  3.1,  1.5,  0.2],\n",
       "       [ 1. ,  5. ,  3.6,  1.4,  0.2],\n",
       "       [ 1. ,  5.4,  3.9,  1.7,  0.4],\n",
       "       [ 1. ,  4.6,  3.4,  1.4,  0.3],\n",
       "       [ 1. ,  5. ,  3.4,  1.5,  0.2],\n",
       "       [ 1. ,  4.4,  2.9,  1.4,  0.2],\n",
       "       [ 1. ,  4.9,  3.1,  1.5,  0.1],\n",
       "       [ 1. ,  5.4,  3.7,  1.5,  0.2],\n",
       "       [ 1. ,  4.8,  3.4,  1.6,  0.2],\n",
       "       [ 1. ,  4.8,  3. ,  1.4,  0.1],\n",
       "       [ 1. ,  4.3,  3. ,  1.1,  0.1],\n",
       "       [ 1. ,  5.8,  4. ,  1.2,  0.2],\n",
       "       [ 1. ,  5.7,  4.4,  1.5,  0.4],\n",
       "       [ 1. ,  5.4,  3.9,  1.3,  0.4],\n",
       "       [ 1. ,  5.1,  3.5,  1.4,  0.3],\n",
       "       [ 1. ,  5.7,  3.8,  1.7,  0.3],\n",
       "       [ 1. ,  5.1,  3.8,  1.5,  0.3],\n",
       "       [ 1. ,  5.4,  3.4,  1.7,  0.2],\n",
       "       [ 1. ,  5.1,  3.7,  1.5,  0.4],\n",
       "       [ 1. ,  4.6,  3.6,  1. ,  0.2],\n",
       "       [ 1. ,  5.1,  3.3,  1.7,  0.5],\n",
       "       [ 1. ,  4.8,  3.4,  1.9,  0.2],\n",
       "       [ 1. ,  5. ,  3. ,  1.6,  0.2],\n",
       "       [ 1. ,  5. ,  3.4,  1.6,  0.4],\n",
       "       [ 1. ,  5.2,  3.5,  1.5,  0.2],\n",
       "       [ 1. ,  5.2,  3.4,  1.4,  0.2],\n",
       "       [ 1. ,  4.7,  3.2,  1.6,  0.2],\n",
       "       [ 1. ,  4.8,  3.1,  1.6,  0.2],\n",
       "       [ 1. ,  5.4,  3.4,  1.5,  0.4],\n",
       "       [ 1. ,  5.2,  4.1,  1.5,  0.1],\n",
       "       [ 1. ,  5.5,  4.2,  1.4,  0.2],\n",
       "       [ 1. ,  4.9,  3.1,  1.5,  0.1],\n",
       "       [ 1. ,  5. ,  3.2,  1.2,  0.2],\n",
       "       [ 1. ,  5.5,  3.5,  1.3,  0.2],\n",
       "       [ 1. ,  4.9,  3.1,  1.5,  0.1],\n",
       "       [ 1. ,  4.4,  3. ,  1.3,  0.2],\n",
       "       [ 1. ,  5.1,  3.4,  1.5,  0.2],\n",
       "       [ 1. ,  5. ,  3.5,  1.3,  0.3],\n",
       "       [ 1. ,  4.5,  2.3,  1.3,  0.3],\n",
       "       [ 1. ,  4.4,  3.2,  1.3,  0.2],\n",
       "       [ 1. ,  5. ,  3.5,  1.6,  0.6],\n",
       "       [ 1. ,  5.1,  3.8,  1.9,  0.4],\n",
       "       [ 1. ,  4.8,  3. ,  1.4,  0.3],\n",
       "       [ 1. ,  5.1,  3.8,  1.6,  0.2],\n",
       "       [ 1. ,  4.6,  3.2,  1.4,  0.2],\n",
       "       [ 1. ,  5.3,  3.7,  1.5,  0.2],\n",
       "       [ 1. ,  5. ,  3.3,  1.4,  0.2],\n",
       "       [ 1. ,  7. ,  3.2,  4.7,  1.4],\n",
       "       [ 1. ,  6.4,  3.2,  4.5,  1.5],\n",
       "       [ 1. ,  6.9,  3.1,  4.9,  1.5],\n",
       "       [ 1. ,  5.5,  2.3,  4. ,  1.3],\n",
       "       [ 1. ,  6.5,  2.8,  4.6,  1.5],\n",
       "       [ 1. ,  5.7,  2.8,  4.5,  1.3],\n",
       "       [ 1. ,  6.3,  3.3,  4.7,  1.6],\n",
       "       [ 1. ,  4.9,  2.4,  3.3,  1. ],\n",
       "       [ 1. ,  6.6,  2.9,  4.6,  1.3],\n",
       "       [ 1. ,  5.2,  2.7,  3.9,  1.4],\n",
       "       [ 1. ,  5. ,  2. ,  3.5,  1. ],\n",
       "       [ 1. ,  5.9,  3. ,  4.2,  1.5],\n",
       "       [ 1. ,  6. ,  2.2,  4. ,  1. ],\n",
       "       [ 1. ,  6.1,  2.9,  4.7,  1.4],\n",
       "       [ 1. ,  5.6,  2.9,  3.6,  1.3],\n",
       "       [ 1. ,  6.7,  3.1,  4.4,  1.4],\n",
       "       [ 1. ,  5.6,  3. ,  4.5,  1.5],\n",
       "       [ 1. ,  5.8,  2.7,  4.1,  1. ],\n",
       "       [ 1. ,  6.2,  2.2,  4.5,  1.5],\n",
       "       [ 1. ,  5.6,  2.5,  3.9,  1.1],\n",
       "       [ 1. ,  5.9,  3.2,  4.8,  1.8],\n",
       "       [ 1. ,  6.1,  2.8,  4. ,  1.3],\n",
       "       [ 1. ,  6.3,  2.5,  4.9,  1.5],\n",
       "       [ 1. ,  6.1,  2.8,  4.7,  1.2],\n",
       "       [ 1. ,  6.4,  2.9,  4.3,  1.3],\n",
       "       [ 1. ,  6.6,  3. ,  4.4,  1.4],\n",
       "       [ 1. ,  6.8,  2.8,  4.8,  1.4],\n",
       "       [ 1. ,  6.7,  3. ,  5. ,  1.7],\n",
       "       [ 1. ,  6. ,  2.9,  4.5,  1.5],\n",
       "       [ 1. ,  5.7,  2.6,  3.5,  1. ],\n",
       "       [ 1. ,  5.5,  2.4,  3.8,  1.1],\n",
       "       [ 1. ,  5.5,  2.4,  3.7,  1. ],\n",
       "       [ 1. ,  5.8,  2.7,  3.9,  1.2],\n",
       "       [ 1. ,  6. ,  2.7,  5.1,  1.6],\n",
       "       [ 1. ,  5.4,  3. ,  4.5,  1.5],\n",
       "       [ 1. ,  6. ,  3.4,  4.5,  1.6],\n",
       "       [ 1. ,  6.7,  3.1,  4.7,  1.5],\n",
       "       [ 1. ,  6.3,  2.3,  4.4,  1.3],\n",
       "       [ 1. ,  5.6,  3. ,  4.1,  1.3],\n",
       "       [ 1. ,  5.5,  2.5,  4. ,  1.3],\n",
       "       [ 1. ,  5.5,  2.6,  4.4,  1.2],\n",
       "       [ 1. ,  6.1,  3. ,  4.6,  1.4],\n",
       "       [ 1. ,  5.8,  2.6,  4. ,  1.2],\n",
       "       [ 1. ,  5. ,  2.3,  3.3,  1. ],\n",
       "       [ 1. ,  5.6,  2.7,  4.2,  1.3],\n",
       "       [ 1. ,  5.7,  3. ,  4.2,  1.2],\n",
       "       [ 1. ,  5.7,  2.9,  4.2,  1.3],\n",
       "       [ 1. ,  6.2,  2.9,  4.3,  1.3],\n",
       "       [ 1. ,  5.1,  2.5,  3. ,  1.1],\n",
       "       [ 1. ,  5.7,  2.8,  4.1,  1.3]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
