{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import collocations\n",
    "from nltk.collocations import *\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scrape Page Text\n",
    "url = \"https://en.wikipedia.org/wiki/N-gram\"\n",
    "page = urllib2.urlopen(url)\n",
    "soup = BeautifulSoup(page).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Format Text\n",
    "joined = ' '.join(soup.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove Punctuation from Word Set\n",
    "exclude = set(string.punctuation)\n",
    "without_punctuation = ''.join(ch for ch in joined if ch not in exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'2011All', u'articles', u'lacking'),\n",
       " (u'2011Articles', u'with', u'specifically'),\n",
       " (u'CS1', u'maint', u'Explicit'),\n",
       " (u'Explicit', u'use', u'of'),\n",
       " (u'Natural', u'Language', u'Processing'),\n",
       " (u'also', u'be', u'used'),\n",
       " (u'an', u'ngram', u'model'),\n",
       " (u'be', u'or', u'not'),\n",
       " (u'be', u'used', u'for'),\n",
       " (u'be', u'\\u2026', u'\\u2026'),\n",
       " (u'can', u'also', u'be'),\n",
       " (u'have', u'been', u'used'),\n",
       " (u'maint', u'Explicit', u'use'),\n",
       " (u'marked', u'weaselworded', u'phrases'),\n",
       " (u'n', u'\\u2212', u'1'),\n",
       " (u'natural', u'language', u'processing'),\n",
       " (u'ngram', u'models', u'are'),\n",
       " (u'not', u'to', u'be'),\n",
       " (u'of', u'a', u'possible'),\n",
       " (u'or', u'not', u'to'),\n",
       " (u'part', u'of', u'the'),\n",
       " (u'serve', u'as', u'the'),\n",
       " (u'specifically', u'marked', u'weaselworded'),\n",
       " (u'to', u'be', u'or'),\n",
       " (u'to', u'be', u'\\u2026'),\n",
       " (u'use', u'of', u'et'),\n",
       " (u'weaselworded', u'phrases', u'from'),\n",
       " (u'with', u'specifically', u'marked'),\n",
       " (u'\\u2026', u'to', u'be'),\n",
       " (u'\\u2026', u'\\u2026', u'to')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply NLTK Trigram Finder\n",
    "tokens = nltk.wordpunct_tokenize(without_punctuation)\n",
    "finder = TrigramCollocationFinder.from_words(tokens)\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "scored = finder.score_ngrams(trigram_measures.raw_freq)\n",
    "set(trigram for trigram, score in scored) == set(nltk.trigrams(tokens))\n",
    "sorted(finder.nbest(trigram_measures.raw_freq, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
