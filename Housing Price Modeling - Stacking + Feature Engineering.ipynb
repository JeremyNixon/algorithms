{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from collections import Counter\n",
    "import sklearn.cross_validation\n",
    "import math\n",
    "import time\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import RandomizedLasso\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_sci_snippet.csv']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_sci_snippet.csv']\n"
     ]
    }
   ],
   "source": [
    "filename = \"data_sci_snippet.csv.zip\"\n",
    "zf = zipfile.ZipFile(filename, 'r')\n",
    "print zf.namelist()\n",
    "\n",
    "def time_preprocessing(df, column_name):\n",
    "    \n",
    "    times = []\n",
    "    count = 0\n",
    "    start = time.time()\n",
    "    for i in df[column_name]:\n",
    "        count += 1\n",
    "        if count % 100000 == 0:\n",
    "            time_elapsed = time.time() - start\n",
    "            #print \"Count = %r, Time Elapsed = %r\" %(count, time_elapsed)\n",
    "        times.append(time.strptime(i, \"%Y-%m-%d\"))\n",
    "\n",
    "    year = []\n",
    "    month = []\n",
    "    day = []\n",
    "    day_of_week = []\n",
    "    day_in_year = []\n",
    "\n",
    "    for i in times:\n",
    "        year.append(i[0])\n",
    "        month.append(i[1])\n",
    "        day.append(i[2])\n",
    "        day_of_week.append(i[6])\n",
    "        day_in_year.append(i[7])\n",
    "    df[column_name + ' year'] = year\n",
    "    df[column_name + ' month'] = month\n",
    "    df[column_name + ' day'] = day\n",
    "    df[column_name + ' day_of_week'] = day_of_week\n",
    "    df[column_name + ' day_in_year'] = day_in_year\n",
    "    df.drop([column_name], axis=1)\n",
    "    return df\n",
    "\n",
    "data = pd.read_csv(zf.open('data_sci_snippet.csv'))\n",
    "\n",
    "one_hot_columns = ['Pool','ListingStatus','DwellingType']\n",
    "count = 0\n",
    "for i in one_hot_columns:\n",
    "    dummies = pd.get_dummies(data[i])\n",
    "    for j in dummies:\n",
    "        data[j] = dummies[j]\n",
    "        count += 1\n",
    "\n",
    "data = time_preprocessing(data, 'ListDate')\n",
    "data = data.dropna()\n",
    "\n",
    "# Note that we won't have closedate in our test data\n",
    "# Could still build a model for closing date and use that as a feature\n",
    "#data = time_preprocessing(data, 'CloseDate')\n",
    "data = data.drop(['CloseDate'], 1)\n",
    "\n",
    "# Remove Outliers\n",
    "data = data[(data['ClosePrice'] > 10000)]\n",
    "data = data[(data['ClosePrice'] < 500000)]\n",
    "data = data[(data['ListPrice'] <= 7000000)]\n",
    "\n",
    "data = data.drop(['Pool', 'ListingStatus', 'DwellingType', 'ListDate', 'PublicRemarks', 'ListDate year'], axis=1)\n",
    "\n",
    "data['ListPrice'] = np.log(data['ListPrice'])\n",
    "data['ClosePrice'] = np.log(data['ClosePrice'])\n",
    "preprocessing_array = []\n",
    "for i in data:\n",
    "    if i == 'ClosePrice':\n",
    "        closeprice_mean = data[i].mean()\n",
    "        closeprice_std = data[i].std()\n",
    "    preprocessing_array.append([i, data[i].mean(), data[i].std()])\n",
    "    data[i] = data[i] - data[i].mean()\n",
    "    data[i] = data[i]/float(data[i].std())\n",
    "\n",
    "def unprocess(data, mean = closeprice_mean, std = closeprice_std):\n",
    "    return np.exp(data*closeprice_std+closeprice_mean)\n",
    "\n",
    "y = data['ClosePrice']\n",
    "x = data.drop(['ClosePrice'], 1)\n",
    "columns = data.columns\n",
    "x_train, x_test, y_train, y_test = sklearn.cross_validation.train_test_split(\n",
    "    x, y, test_size=0.02, random_state=14)\n",
    "\n",
    "data = pd.DataFrame(x_train, columns=columns[:-1])\n",
    "data['ClosePrice'] = y_train\n",
    "test_data = pd.DataFrame(x_test, columns=columns[:-1])\n",
    "test_data['ClosePrice'] = y_test\n",
    "\n",
    "full = pd.DataFrame()\n",
    "for_test = pd.DataFrame()\n",
    "for i in data:\n",
    "    for j in data:\n",
    "        if i != 'ClosePrice' and j != 'ClosePrice':\n",
    "            full[i + '*' + j] = data[i]*data[j]\n",
    "            for_test[i + '*' + j] = test_data[i]*test_data[j]\n",
    "full['ClosePrice'] = data['ClosePrice']\n",
    "correlations = full.corrwith(full['ClosePrice'])\n",
    "columns = full.columns\n",
    "for i in range(len(correlations)):\n",
    "    if abs(list(correlations)[i]) > .3:\n",
    "        data[columns[i]] = full[columns[i]]\n",
    "        if columns[i] != 'ClosePrice':\n",
    "            test_data[columns[i]] = for_test[columns[i]]\n",
    "\n",
    "stacking_data = data[:len(data)/2]\n",
    "training_data = data[len(data)/2:]\n",
    "\n",
    "x_train_stacking = stacking_data[[\n",
    "                    'LivingArea',\n",
    "                    'NumBedrooms',\n",
    "                    'NumBaths',\n",
    "                    'ExteriorStories',\n",
    "                    'ListPrice',\n",
    "                    'GeoLat',\n",
    "                    'GeoLon',\n",
    "                    'Both Private & Community',\n",
    "                    'Private',\n",
    "                    'Apartment Style/Flat',\n",
    "                    'Gemini/Twin Home',\n",
    "                    'Single Family - Detached',\n",
    "                    'Townhouse',\n",
    "#                 'ListPrice*ListPrice',\n",
    "#                  'ListPrice*Single Family - Detached',\n",
    "#                  'Community*None',\n",
    "#                  'None*Community',\n",
    "#                  'Private*Private',\n",
    "#                  'Apartment Style/Flat*Mfg/Mobile Housing',\n",
    "#                  'Apartment Style/Flat*Townhouse',\n",
    "#                  'Mfg/Mobile Housing*Apartment Style/Flat',\n",
    "#                  'Mfg/Mobile Housing*Townhouse',\n",
    "#                  'Single Family - Detached*ListPrice',\n",
    "#                  'Single Family - Detached*Single Family - Detached',\n",
    "#                  'Townhouse*Apartment Style/Flat',\n",
    "#                  'Townhouse*Mfg/Mobile Housing'\n",
    "               ]]\n",
    "y_train_stacking = stacking_data['ClosePrice']\n",
    "\n",
    "x_train_training = training_data[[\n",
    "                    'LivingArea',\n",
    "                    'NumBedrooms',\n",
    "                    'NumBaths',\n",
    "                    'ExteriorStories',\n",
    "                    'ListPrice',\n",
    "                    'GeoLat',\n",
    "                    'GeoLon',\n",
    "                    'Both Private & Community',\n",
    "                    'Private',\n",
    "                    'Apartment Style/Flat',\n",
    "                    'Gemini/Twin Home',\n",
    "                    'Single Family - Detached',\n",
    "                    'Townhouse',\n",
    "#                      'ListPrice*ListPrice',\n",
    "#                      'ListPrice*Single Family - Detached',\n",
    "#                      'Community*None',\n",
    "#                      'None*Community',\n",
    "#                      'Private*Private',\n",
    "#                      'Apartment Style/Flat*Mfg/Mobile Housing',\n",
    "#                      'Apartment Style/Flat*Townhouse',\n",
    "#                      'Mfg/Mobile Housing*Apartment Style/Flat',\n",
    "#                      'Mfg/Mobile Housing*Townhouse',\n",
    "#                      'Single Family - Detached*ListPrice',\n",
    "#                      'Single Family - Detached*Single Family - Detached',\n",
    "#                      'Townhouse*Apartment Style/Flat',\n",
    "#                      'Townhouse*Mfg/Mobile Housing'\n",
    "               ]]\n",
    "y_train_training = training_data['ClosePrice']\n",
    "\n",
    "x_test_listprice = test_data[[\n",
    "                    'LivingArea',\n",
    "                    'NumBedrooms',\n",
    "                    'NumBaths',\n",
    "                    'ExteriorStories',\n",
    "                    'ListPrice',\n",
    "                    'GeoLat',\n",
    "                    'GeoLon',\n",
    "                    'Both Private & Community',\n",
    "                    'Private',\n",
    "                    'Apartment Style/Flat',\n",
    "                    'Gemini/Twin Home',\n",
    "                    'Single Family - Detached',\n",
    "                    'Townhouse',\n",
    "#                      'ListPrice*ListPrice',\n",
    "#                      'ListPrice*Single Family - Detached',\n",
    "#                      'Community*None',\n",
    "#                      'None*Community',\n",
    "#                      'Private*Private',\n",
    "#                      'Apartment Style/Flat*Mfg/Mobile Housing',\n",
    "#                      'Apartment Style/Flat*Townhouse',\n",
    "#                      'Mfg/Mobile Housing*Apartment Style/Flat',\n",
    "#                      'Mfg/Mobile Housing*Townhouse',\n",
    "#                      'Single Family - Detached*ListPrice',\n",
    "#                      'Single Family - Detached*Single Family - Detached',\n",
    "#                      'Townhouse*Apartment Style/Flat',\n",
    "#                      'Townhouse*Mfg/Mobile Housing'\n",
    "                   ]]\n",
    "y_test = test_data['ClosePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = data[[\n",
    "                    'LivingArea',\n",
    "                    'NumBedrooms',\n",
    "                    'NumBaths',\n",
    "                    'ExteriorStories',\n",
    "                    'ListPrice',\n",
    "                    'GeoLat',\n",
    "                    'GeoLon',\n",
    "                    'Both Private & Community',\n",
    "                    'Private',\n",
    "                    'Apartment Style/Flat',\n",
    "                    'Gemini/Twin Home',\n",
    "                    'Single Family - Detached',\n",
    "                    'Townhouse'\n",
    "        ]]\n",
    "y_train = data['ClosePrice']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3327.7889718110964, 0.5)\n",
      "(3327.1239794666326, 1.0)\n",
      "(3326.4590014815913, 1.5)\n",
      "(3325.7940378605708, 2.0)\n",
      "(3325.1290886081842, 2.5)\n",
      "(3325.8945005880669, 3.0)\n",
      "(3329.749725203088, 3.5)\n",
      "(3333.6045259448583, 4.0)\n",
      "(3335.2371835059894, 4.5)\n",
      "(3332.8939118921407, 5.0)\n",
      "(3330.5509187112038, 5.5)\n",
      "(3328.2082039088418, 6.0)\n",
      "(3325.8657674308051, 6.5)\n",
      "(3323.5236092231353, 7.0)\n",
      "(3321.1817292311171, 7.5)\n",
      "(3318.8401274004718, 8.0)\n",
      "(3317.1768408731441, 8.5)\n",
      "(3319.7007466014184, 9.0)\n",
      "(3323.1485003193666, 9.5)\n",
      "(3326.5958636398136, 10.0)\n",
      "(3330.0428366351698, 10.5)\n",
      "(3333.4894193774089, 11.0)\n",
      "(3336.9356119397853, 11.5)\n",
      "(3340.3814143933996, 12.0)\n",
      "(3343.8268268110405, 12.5)\n",
      "(3347.2718492651184, 13.0)\n",
      "(3350.7164818275487, 13.5)\n",
      "(3354.1607245702762, 14.0)\n",
      "(3354.7009008867317, 14.5)\n",
      "(3355.1294737665157, 15.0)\n",
      "(3355.5579501924512, 15.5)\n",
      "(3355.9863301907026, 16.0)\n",
      "(3356.4146137880743, 16.5)\n",
      "(3356.8428010101488, 17.0)\n",
      "(3357.2708918836724, 17.5)\n",
      "(3357.6988864342857, 18.0)\n",
      "(3358.126784689026, 18.5)\n",
      "(3358.068211809441, 19.0)\n",
      "(3356.941144733486, 19.5)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,40):\n",
    "    bayesian_ridge = linear_model.Ridge(alpha = i/2.0)\n",
    "    bayesian_ridge.fit(x_train, y_train)\n",
    "    bayesian_ridge_predictions = bayesian_ridge.predict(x_test_listprice)\n",
    "    median = np.median(abs((unprocess(bayesian_ridge_predictions))-unprocess(y_test)))\n",
    "    print(median, i/2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61046.770500969229, 1.0)\n",
      "(58751.434876406682, 0.95)\n",
      "(56030.296179051162, 0.9)\n",
      "(52184.324801374678, 0.85)\n",
      "(48578.219325049009, 0.8)\n",
      "(45393.772775971302, 0.75)\n",
      "(42402.992651826484, 0.7)\n",
      "(39323.185830956252, 0.65)\n",
      "(36055.276695751643, 0.6)\n",
      "(32403.051240164001, 0.55)\n",
      "(29501.484379176633, 0.5)\n",
      "(26394.122422166693, 0.44999999999999996)\n",
      "(23391.193424511701, 0.4)\n",
      "(20264.940001637442, 0.35)\n",
      "(17349.547580657207, 0.30000000000000004)\n",
      "(14365.188999693215, 0.25)\n",
      "(11500.495800816105, 0.19999999999999996)\n",
      "(8777.9564921767596, 0.15000000000000002)\n",
      "(6449.768017185299, 0.09999999999999998)\n",
      "(4367.9523624748981, 0.050000000000000044)\n",
      "(3328.4539785103989, 0.0)\n",
      "(11332.758809624138, -0.050000000000000044)\n",
      "(22263.762925524105, -0.10000000000000009)\n",
      "(32200.843657212594, -0.1499999999999999)\n",
      "(42183.248053808464, -0.19999999999999996)\n",
      "(52475.359479470964, -0.25)\n",
      "(58885.376959582696, -0.30000000000000004)\n",
      "(67683.086293300119, -0.3500000000000001)\n",
      "(75758.547532147728, -0.3999999999999999)\n",
      "(82361.160252564237, -0.44999999999999996)\n",
      "(88650.800149686344, -0.5)\n",
      "(94320.038667895205, -0.55)\n",
      "(100922.61088425858, -0.6000000000000001)\n",
      "(106848.31310672034, -0.6499999999999999)\n",
      "(111740.80566487218, -0.7)\n",
      "(117298.12222743247, -0.75)\n",
      "(121715.7162536354, -0.8)\n",
      "(125701.73492133134, -0.8500000000000001)\n",
      "(132069.36717813776, -0.8999999999999999)\n",
      "(137534.26278495102, -0.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremynixon/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:3: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,40):\n",
    "    bayesian_ridge = linear_model.Lasso(alpha = 1-i/20.0)\n",
    "    bayesian_ridge.fit(x_train, y_train)\n",
    "    bayesian_ridge_predictions = bayesian_ridge.predict(x_test_listprice)\n",
    "    median = np.median(abs((unprocess(bayesian_ridge_predictions))-unprocess(y_test)))\n",
    "    print(median, 1-i/20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LivingArea</th>\n",
       "      <th>NumBedrooms</th>\n",
       "      <th>NumBaths</th>\n",
       "      <th>ExteriorStories</th>\n",
       "      <th>ListPrice</th>\n",
       "      <th>GeoLat</th>\n",
       "      <th>GeoLon</th>\n",
       "      <th>Both Private &amp; Community</th>\n",
       "      <th>Private</th>\n",
       "      <th>Apartment Style/Flat</th>\n",
       "      <th>Gemini/Twin Home</th>\n",
       "      <th>Single Family - Detached</th>\n",
       "      <th>Townhouse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.744707</td>\n",
       "      <td> 0.904503</td>\n",
       "      <td>-0.080494</td>\n",
       "      <td>-0.426973</td>\n",
       "      <td>-0.323824</td>\n",
       "      <td> 0.661435</td>\n",
       "      <td>-0.354584</td>\n",
       "      <td>-0.592229</td>\n",
       "      <td>-0.039833</td>\n",
       "      <td>-0.085409</td>\n",
       "      <td>-0.027647</td>\n",
       "      <td>-0.276699</td>\n",
       "      <td>-0.777024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 0.183095</td>\n",
       "      <td>-0.221713</td>\n",
       "      <td>-0.038193</td>\n",
       "      <td>-0.426973</td>\n",
       "      <td> 0.534670</td>\n",
       "      <td> 0.038596</td>\n",
       "      <td>-1.172749</td>\n",
       "      <td>-0.592229</td>\n",
       "      <td>-0.039833</td>\n",
       "      <td>-0.085409</td>\n",
       "      <td>-0.027647</td>\n",
       "      <td>-0.276699</td>\n",
       "      <td>-0.777024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 0.115537</td>\n",
       "      <td> 0.904503</td>\n",
       "      <td>-0.038193</td>\n",
       "      <td>-0.426973</td>\n",
       "      <td> 0.431430</td>\n",
       "      <td> 0.003389</td>\n",
       "      <td>-1.185919</td>\n",
       "      <td>-0.592229</td>\n",
       "      <td>-0.039833</td>\n",
       "      <td>-0.085409</td>\n",
       "      <td>-0.027647</td>\n",
       "      <td>-0.276699</td>\n",
       "      <td> 0.984511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 1.345100</td>\n",
       "      <td> 2.030719</td>\n",
       "      <td> 0.131012</td>\n",
       "      <td> 0.843059</td>\n",
       "      <td> 1.178876</td>\n",
       "      <td> 0.005641</td>\n",
       "      <td> 1.160108</td>\n",
       "      <td> 1.688488</td>\n",
       "      <td>-0.039833</td>\n",
       "      <td>-0.085409</td>\n",
       "      <td>-0.027647</td>\n",
       "      <td>-0.276699</td>\n",
       "      <td>-0.777024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.477476</td>\n",
       "      <td>-0.221713</td>\n",
       "      <td>-0.038193</td>\n",
       "      <td>-0.426973</td>\n",
       "      <td>-0.449216</td>\n",
       "      <td> 0.603690</td>\n",
       "      <td>-1.353673</td>\n",
       "      <td>-0.592229</td>\n",
       "      <td>-0.039833</td>\n",
       "      <td>-0.085409</td>\n",
       "      <td>-0.027647</td>\n",
       "      <td>-0.276699</td>\n",
       "      <td> 1.571689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LivingArea  NumBedrooms  NumBaths  ExteriorStories  ListPrice    GeoLat  \\\n",
       "0   -0.744707     0.904503 -0.080494        -0.426973  -0.323824  0.661435   \n",
       "1    0.183095    -0.221713 -0.038193        -0.426973   0.534670  0.038596   \n",
       "2    0.115537     0.904503 -0.038193        -0.426973   0.431430  0.003389   \n",
       "3    1.345100     2.030719  0.131012         0.843059   1.178876  0.005641   \n",
       "4   -0.477476    -0.221713 -0.038193        -0.426973  -0.449216  0.603690   \n",
       "\n",
       "     GeoLon  Both Private & Community   Private  Apartment Style/Flat  \\\n",
       "0 -0.354584                 -0.592229 -0.039833             -0.085409   \n",
       "1 -1.172749                 -0.592229 -0.039833             -0.085409   \n",
       "2 -1.185919                 -0.592229 -0.039833             -0.085409   \n",
       "3  1.160108                  1.688488 -0.039833             -0.085409   \n",
       "4 -1.353673                 -0.592229 -0.039833             -0.085409   \n",
       "\n",
       "   Gemini/Twin Home  Single Family - Detached  Townhouse  \n",
       "0         -0.027647                 -0.276699  -0.777024  \n",
       "1         -0.027647                 -0.276699  -0.777024  \n",
       "2         -0.027647                 -0.276699   0.984511  \n",
       "3         -0.027647                 -0.276699  -0.777024  \n",
       "4         -0.027647                 -0.276699   1.571689  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ridge_regression(x_train, y_train, x_test, lam):\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_test = np.array(x_test)\n",
    "    \n",
    "    x = np.column_stack((np.ones(len(x_train)), x_train))\n",
    "    y = y_train\n",
    "    \n",
    "    #((XtX + lambda I)^-1 * Xt*y)\n",
    "    \n",
    "    xt = np.transpose(x)\n",
    "    product = np.dot(xt, x)\n",
    "    lambda_identity = lam*np.identity(len(xt))\n",
    "    inverse = np.linalg.inv(product + lambda_identity)\n",
    "    weights = np.dot(np.dot(inverse, xt), y)\n",
    "    \n",
    "    predictions = []\n",
    "    for i in x_test:\n",
    "        evaluated = sum(i*weights[1:])\n",
    "        predictions.append(evaluated + weights[0])\n",
    "    \n",
    "    return predictions\n",
    "    \n",
    "ridge_predictions = ridge_regression(x_train, y_train, x_test_listprice, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3318.8369380600052"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median = np.median(abs((unprocess(np.array(ridge_predictions)))-unprocess(y_test)))\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3498.31285086\n",
      "[ 0.          0.00263044  0.         -0.          0.9840766  -0.         -0.\n",
      " -0.         -0.         -0.          0.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "lasso = linear_model.Lasso(alpha = .01)\n",
    "lasso.fit(x_train, y_train)\n",
    "lasso_predictions = lasso.predict(x_test_listprice)\n",
    "median = np.median(abs((unprocess(lasso_predictions))-unprocess(y_test)))\n",
    "print(median)\n",
    "print lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.19259979e-03,   1.05397289e-02,   8.92793863e-04,\n",
       "        -8.58661699e-04,   9.95361344e-01,  -5.54372162e-03,\n",
       "        -6.33059272e-03,  -1.67210647e-03,  -5.20435984e-03,\n",
       "        -1.12831245e-03,   4.23844344e-04,  -2.49722753e-03,\n",
       "         5.54819505e-04])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_ridge = linear_model.Ridge(alpha = 8)\n",
    "bayesian_ridge.fit(x_train, y_train)\n",
    "bayesian_ridge_predictions = bayesian_ridge.predict(x_test_listprice)\n",
    "median = np.median(abs((unprocess(bayesian_ridge_predictions))-unprocess(y_test)))\n",
    "bayesian_ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median = 3280.039948568301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremynixon/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jeremynixon/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "bayesian_ridge = linear_model.Ridge()\n",
    "bayesian_ridge.fit(x_train_stacking, y_train_stacking)\n",
    "bayesian_ridge_predictions_test = bayesian_ridge.predict(x_test_listprice)\n",
    "\n",
    "bayesian_ridge = linear_model.Ridge()\n",
    "bayesian_ridge.fit(x_train_stacking, y_train_stacking)\n",
    "bayesian_ridge_predictions_stacking = bayesian_ridge.predict(x_train_training)\n",
    "\n",
    "x_train_training['Bayesian_Ridge_Predictions'] = bayesian_ridge_predictions_stacking\n",
    "x_test_listprice['Bayesian_Ridge_Predictions'] = bayesian_ridge_predictions_test\n",
    "\n",
    "booster = ensemble.GradientBoostingRegressor(n_estimators = 110)\n",
    "booster.fit(x_train_training, y_train_training)\n",
    "booster_predictions = booster.predict(x_test_listprice)\n",
    "\n",
    "forest = ensemble.RandomForestRegressor(n_estimators = 100)\n",
    "forest.fit(x_train_training, y_train_training)\n",
    "forest_predictions = booster.predict(x_test_listprice)\n",
    "\n",
    "median = np.median(abs((unprocess(booster_predictions)+unprocess(forest_predictions))/2.0-unprocess(y_test)))\n",
    "print \"Median = %r\" %median"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
