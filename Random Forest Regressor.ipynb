{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('movie_data.csv', index_col=0)\n",
    "y = np.array(data.ix[:, 'box_office'].values)\n",
    "X = np.array(data.drop('box_office', 1))\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self, parents=None):\n",
    "        self.children = []\n",
    "        self.split_feature = None\n",
    "        self.split_feature_value = None\n",
    "        self.parents = parents\n",
    "        self.label = None\n",
    "\n",
    "def std_reduction(y_train):\n",
    "    return -np.std(y_train)\n",
    "\n",
    "def split_data(x_train, y_train, feature_index):\n",
    "    attribute_values = x_train[:,feature_index]\n",
    "    for attribute in set(attribute_values):\n",
    "        data_subset = []\n",
    "        for index, point in enumerate(x_train):\n",
    "            if point[feature_index] == attribute:\n",
    "                data_subset.append([point, y_train[index]])\n",
    "        yield data_subset\n",
    "\n",
    "def gain(x_train, y_train, feature_index):\n",
    "    reduction = std_reduction(y_train)\n",
    "    for data_subset in split_data(x_train, y_train, feature_index):\n",
    "        reduction -= std_reduction([label\n",
    "                    for (point, label) in data_subset])\n",
    "    return reduction\n",
    "\n",
    "def homogeneous(y_train):\n",
    "    return len(set(y_train)) <= 1\n",
    "\n",
    "def majority_vote(y_train, node):\n",
    "    labels = y_train\n",
    "    choice = max(set(labels), key=list(labels).count)\n",
    "    node.label = choice\n",
    "    return node\n",
    "\n",
    "def build_decision_tree(x_train, y_train, root, remaining_features):\n",
    "    remaining_features = np.array(list(remaining_features))\n",
    "    if homogeneous(y_train):\n",
    "        root.label = y_train[0]\n",
    "        return root\n",
    "    \n",
    "    if remaining_features.shape == 0:\n",
    "        return majority_vote(y_train, root)\n",
    "    \n",
    "    indices = np.random.choice(int(remaining_features.shape[0]), int(2*remaining_features.shape[0]/3), replace = False)\n",
    "\n",
    "    best_feature = max(remaining_features[indices], key=lambda index: \n",
    "                       gain(x_train, y_train, index))\n",
    "    remaining_features = set(remaining_features)\n",
    "    if gain(x_train, y_train, best_feature) == 0:\n",
    "        return majority_vote(y_train, root)\n",
    "    \n",
    "    root.split_feature = best_feature\n",
    "    \n",
    "    for data_subset in split_data(x_train, y_train, best_feature):\n",
    "        child = Tree(parents = root)\n",
    "        child.split_feature_value = data_subset[0][0][best_feature]\n",
    "        root.children.append(child)\n",
    "        \n",
    "        new_x = np.array([point for (point, label) in data_subset])\n",
    "        new_y = np.array([label for (point, label) in data_subset])\n",
    "        \n",
    "        build_decision_tree(new_x, new_y, child, remaining_features - set([best_feature]))\n",
    "    \n",
    "    return root\n",
    "\n",
    "def decision_tree(x_train, y_train):\n",
    "    return build_decision_tree(x_train, y_train, Tree(), \n",
    "                               set(range(len(x_train[0]))))\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    nearest = (np.abs(array-value)).argmin()\n",
    "    return array[nearest]\n",
    "\n",
    "def evaluate(tree, point):\n",
    "    if tree.children == []:\n",
    "#         print \"label = %r\" %(tree.label)\n",
    "        return tree.label\n",
    "    else:\n",
    "        try:\n",
    "            matching_children = [child for child in tree.children\n",
    "                if child.split_feature_value == point[tree.split_feature]]\n",
    "            return evaluate(matching_children[0], point)\n",
    "        except:\n",
    "            array = [child.split_feature_value for child in tree.children]\n",
    "            point[tree.split_feature] = find_nearest(array, point[tree.split_feature])\n",
    "            matching_children = [child for child in tree.children\n",
    "                if child.split_feature_value == point[tree.split_feature]]\n",
    "            return evaluate(matching_children[0], point)\n",
    "        \n",
    "def predict(x_test, tree):\n",
    "    predicted_labels = [evaluate(tree, point) for point in x_test]\n",
    "    return predicted_labels\n",
    "\n",
    "def random_forest(x_train, y_train, x_test, n_estimators = 100):\n",
    "    x_train_copy = x_train\n",
    "    y_train_copy = y_train\n",
    "    x_test_copy = x_test\n",
    "    labels = []\n",
    "    sample = []\n",
    "    predictions = []\n",
    "    for i in range(n_estimators):\n",
    "        sample.append(np.random.choice(len(x_train), len(x_train),\n",
    "                                       replace=True))\n",
    "    for i in range(n_estimators):\n",
    "        x_train = x_train_copy.copy()\n",
    "        y_train = y_train_copy.copy()\n",
    "        x_test_copy = x_test_copy.copy()\n",
    "        \n",
    "        x = x_train[sample[i]]\n",
    "        y = y_train[sample[i]]\n",
    "        tree = decision_tree(x, y)\n",
    "        labels.append(predict(x_test_copy, tree))\n",
    "    \n",
    "    for index in range(len(labels[0])):\n",
    "        predictions.append(np.median([item[index] for item in labels]))\n",
    "        \n",
    "    return predictions, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions, labels = random_forest(x_train, y_train, x_test, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modeling\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "y_hat = model.fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "\n",
    "forest = ensemble.RandomForestRegressor(n_estimators = 100)\n",
    "forest_predictions = forest.fit(x_train, y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sci-kit Learn RF:\n",
      "2118848.58287\n",
      "Sci-kit Learn Linear Regression:\n",
      "4096437.88812\n",
      "Scratch RF:\n",
      "5228027.07391\n"
     ]
    }
   ],
   "source": [
    "# Scikit Learn RF\n",
    "print \"Sci-kit Learn RF:\"\n",
    "print metrics.mean_absolute_error(y_test, forest_predictions)\n",
    "\n",
    "# Scikit Learn LR\n",
    "print \"Sci-kit Learn Linear Regression:\"\n",
    "print(metrics.mean_absolute_error(y_test, y_hat))\n",
    "\n",
    "# Scratch RF\n",
    "print \"Scratch RF:\"\n",
    "print(metrics.mean_absolute_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
